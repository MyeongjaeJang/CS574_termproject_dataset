Abstract Background Genotype-phenotype association has been one of the long-standing problems in bioinformatics. Identifying both the marginal and epistatic effects among genetic markers, such as Single Nucleotide Polymorphisms (SNPs), has been extensively integrated in Genome-Wide Association Studies (GWAS) to help derive “causal” genetic risk factors and their interactions, which play critical roles in life and disease systems. Identifying “synergistic” interactions with respect to the outcome of interest can help accurate phenotypic prediction and understand the underlying mechanism of system behavior. Many statistical measures for estimating synergistic interactions have been proposed in the literature for such a purpose. However, except for empirical performance, there is still no theoretical analysis on the power and limitation of these synergistic interaction measures. Results In this paper, it is shown that the existing information-theoretic multivariate synergy depends on a small subset of the interaction parameters in the model, sometimes on only one interaction parameter. In addition, an adjusted version of multivariate synergy is proposed as a new measure to estimate the interactive effects, with experiments conducted over both simulated data sets and a real-world GWAS data set to show the effectiveness. Conclusions We provide rigorous theoretical analysis and empirical evidence on why the information-theoretic multivariate synergy helps with identifying genetic risk factors via synergistic interactions. We further establish the rigorous sample complexity analysis on detecting interactive effects, confirmed by both simulated and real-world data sets. Keywords Genotype-phenotype association Feature selection Genome-wide association study Synergistic interaction Mutual information Background With the outburst of high-throughput omics data [ 1 – 7 ], there is a pressing need for big data analytics to develop statistical learning algorithms to derive reproducible research findings from extremely high-dimensional data, such that we can better understand complex life and disease systems. Among many analytic problems for big biomedical data, understanding genotype-phenotype relationships is one of the most critical problems to help identify “causal” risk factors and/or biomarkers, further develop accurate phenotypic prediction models, and derive effective therapeutic strategies. In statistical learning, risk factor or biomarker identification problems can be formulated as feature selection or feature screening [ 8 – 10 ] to identify a subset of profiled variables or features that are significantly associated with the system behavior of interest in a statistical sense. Mathematically, given a set of d profiled variables, denoted by X 1 , X 2 ,…, X d , we search for a subset of them that are statistically associated (based on N sample measurements) with the outcome variable Y , which denotes certain systems behavior, such as disease status and treatment response in biomedicine. Due to the extremely high dimension in modern big data applications, most of the existing feature selection approaches focus on univariate analysis to screen features based on the estimated “individual” or “marginal” effects on the outcome of interest, for example, when looking for genetic risk factors from Single Nucleotide Polymorphisms (SNPs) in many Genome-Wide Association Studies (GWAS) [ 11 ]. However, these analyses focusing on individual effects may not be sufficient as real-world systems often manifest complex behaviors arising from highly coordinated interactions among systems components [ 11 – 15 ]. For example, many complex diseases, such as cancer and diabetes, are conjectured to have complicated underlying disease mechanisms, which are neither static nor linear [ 12 – 20 ]. Multiple candidate risk factors, either genetic or environmental, along with their interactions have been considered to play critical roles in triggering and determining the development of diseases [ 12 – 20 ]. Identifying interactive effects among profiled variables not only helps more accurate identification of critical risk factors or biomarkers for outcome prediction, but also helps reveal functional interactions and understand aberrant system changes that are specifically related to the outcome for effective system intervention. To find important features considering interactive effects, one possible solution is to derive a full Logistic Regression model that incorporates the interactive effects as feature multiplication terms [ 21 ]. However, the model complexity can increase exponentially and hence requires a large number of samples to generate reproducible results. Even with the sparse regularization penalty [ 21 ], model learning can be computationally expensive when considering interaction terms. Recently, in [ 22 ], the authors studied the pairwise interaction in logistic regression models, and establish a rigorous theoretical analysis about how to detect all pairwise interactions. However, they can only deal with the cases when all profiled variables are uniformly distributed, and all pairwise interactions form an acyclic interaction graph. Due to the prohibitive sample complexity and computational cost when considering the full model with different orders of interactions, most of the existing biomarker identification approaches take a two-step procedure: 1) First, some heuristic measures based on correlation, mutual information, or simplified regression models, are adopted to estimate the statistical association among pairs of features and the outcome [ 13 – 20 , 23 , 24 ]; 2) Then, some optimization algorithms including greedy ranking algorithms [ 18 – 20 , 23 , 25 , 26 ] are implemented to select “important” features based on various criteria. Due to different possible ad-hoc choices in these methods, it is quite vague which essential information or interaction among features can be captured. The existing literature mostly provides only empirical performance evaluation of these methods without solid theoretical guarantees. The primary goal of this work is to establish rigorous mathematical theories for feature screening and selection approaches with the consideration of interactive effects under a specific system model based on logistic regression [ 9 , 10 ], which has been arguably the most popular model for biomarker identification and phenotypic classification, for example, in GWAS. We study the definitions of mutual-information-based synergistic effect measures and try to understand why these measures work under specific model assumptions. We specifically look for interactive effects that are contributing multiplication terms among variables in logistic regression, considered as “cooperative interactions”. We derive a family of interactive measures that can provide accurate detection of such cooperative interactions. We theoretically prove that such interactive measures can indeed be approximately written as quadratic functions of the parameters of the cooperative interactions in logistic regression. In addition, we provide a rigorous theoretical sample complexity analysis on such interactive measures. The two-step procedure with these information-theoretic synergistic interaction measures can accurately and robustly identify risk factors with interactive effects without learning the expensive full logistic regression model. Finally, we apply our results in both simulated data sets and a real-world GWAS data set to demonstrate the effectiveness of these information theoretic measures. Methods System model Consider d independent binary profiled variables X 1 , X 2 ,…, X d and a binary outcome variable Y . The profiled variables are assumed to have the probability distribution Pr( X i =+1)= p i and Pr( X i =−1)= q i with p i , q i >0, p i + q i =1 for 1≤ i ≤ d , and the conditional probability of the outcome variable Y is assumed to take the following form: $$ \begin{aligned} \Pr(Y&=1|X_{1},X_{2},\ldots,X_{d})\\ &=\sigma\left(\beta_{\emptyset}+\sum_{\emptyset \subset S\subseteq\{1,2,\ldots,d\}}\beta_{S}\prod_{i\in S} X_{i}\right),\\ \end{aligned} $$ (1) $$ \begin{aligned} \Pr(Y&=-1|X_{1},X_{2},\ldots,X_{d})\\ &=1-\Pr(Y=1|X_{1},X_{2},\ldots,X_{d}), \end{aligned} $$ (2) where σ ( x ):=1/(1+ e − x ) is the sigmoid function and { β S : S ⊆ {1,2,…, d }} is a family of real parameters. For any subset S of {1,2,…, d }, parameter β S measures the amount of the cooperative interaction among the variables X i ’s ( i ∈ S ). We call this model as the “full” model. Assume that all parameters β S are bounded, i.e., | β S |< C for all S ⊆ {1,2,…, d }. It is a highly generic model based on the classical logistic regression model, since it incorporates the cooperative interaction of any subset of profiled variables X 1 , X 2 ,…, X d . We can estimate the cooperative interactions among candidates X i ’s and Y via the help of multivariate information measures, which are suggested to quantify the correlation among two or more random variables. Such measures include multivariate mutual information [ 27 – 32 ], Pearson’s correlation coefficients [ 33 ], and maximal information coefficient [ 34 ]. Multivariate mutual information, an information theoretical [ 35 , 36 ] tool, has a variety of definitions, such as multivariate synergy [ 13 , 14 , 37 ], McGill’s mutual information [ 27 ], Watanabe’s total correlation [ 28 ], Gács-Körner common information [ 29 ], Han’s dual total correlation [ 30 ], and Wyner’s common information [ 31 ]. In [ 32 ], the authors compared the mathematical and information-theoretical properties among many existing multivariate mutual information measures and suggested a new one inspired by multi-terminal secret-key agreement [ 38 ]. In this paper, we mainly focus on the multivariate synergy, first suggested in [ 37 ] (where a different notation “ R S N | N −1 ” was used) and recently proposed for interaction and association studies in bioinformatics by Anastassiou [ 13 ]. Precisely, for any n random variables Z 1 , Z 2 ,…, Z n , the multivariate synergy of these variables is defined to be where H is the Shannon entropy [ 35 , 36 ]. Notice that when n =2, the multivariate synergy is in fact the mutual information of Z 1 and Z 2 [ 35 ], a measure of the dependence between Z 1 and Z 2 in information theory. In the following, we first connect the defined multivariate synergies with cooperative interactions manifested as the coefficients of the corresponding interaction terms in the full logistic regression model. The main theoretical result that we establish is to show why such a multivariate synergy can help risk factor identification with interactions. Based on the connection between multivariate synergy and the interaction terms in the logistic regression model, we further derive the sample complexity for accurate interaction estimation. Estimation of interaction parameters by multivariate synergies We first establish the main theorem, which shows that for any subset S of {1,2,…, d }, the multivariate synergy of \(X_{S}\triangleq \{X_{i}: i\in S\}\) and Y is approaching a quadratic function over parameter β S of the cooperative interaction corresponding to S . Theorem 1 For any subset S ⊆ {1,2,…, d }, Proof See the proof in Additional file 1 . □ The above theorem shows that the multivariate synergy depends only on the interaction parameters β G for G ⊇ S approximately, when C is small enough. For the special case when all profiled variables X i ’s are uniformly distributed, the theorem has a cleaner form as follows. Corollary 2 Assume that each profiled variable X i is uniformly distributed. For any set S ⊆ {1,2,…, d }, we have Proof It quickly follows from Theorem 1 with p i = q i =1/2 for i ∈ G ∖ S . □ From this corollary, it is clear that the multivariate synergy mainly depends on β S when C is small enough. Hence, estimating the multivariate synergy can help identify interactions without inferring the full logistic regression model. For the interactions of the highest order, we have another result in a clean form. Corollary 3 Assume that there is no interaction of orders higher than m , i.e., β G =0 if | G |> m . For any set S ⊆ {1,2,…, d } with order m , we have Proof This follows from Theorem 1 with β G =0 for G ⊃ S . □ This result tells us that the highest-order multivariate synergy mainly depends on β S when C is small enough. This indeed guarantees that when the sample size is large enough, we can correctly estimate the highest-order interactions in logistic regression without actually learning the full model. Based on the above results, we find that the multivariate synergy has a monotonic relationship with the magnitude of the interactive effects in the full logistic regression model, which explains the past empirical results showing that they indeed work in GWAS. In addition, we also notice that such a monotonic relationship can be interfered by the common factor \(\frac {1}{8}\prod _{i\in S} 4p_{i}q_{i}\) , dependent on the distributions of X i in S . To alleviate such interference, we propose an adjusted multivariate synergy , which directly reflects the interactive effect in the logistic regression model with the normalization to adjust for the interference: Definition 4 Adjusted Multivariate Synergy: (3) In the experiments, we will demonstrate that this new proposed measure can accurately and robustly identify interactions from both simulated and real-world GWAS data. Number of samples needed for estimation In this section, we provide the lower bound of the number of samples that we need to ensure the small estimation error of the multivariate synergy. For any variables Z 1 , Z 2 ,…, Z t on {1,−1}, the plug-in estimate \(\widehat {H}_{N}(Z_{1},Z_{2},\ldots,Z_{t})\) of the entropy H ( Z 1 , Z 2 ,…, Z t ) is defined as [ 39 ]: $$\begin{array}{*{20}l} &\widehat{H}_{N}(Z_{1},Z_{2},\ldots,Z_{t})\\ &=-\sum_{z_{1},z_{2},\ldots,z_{t}\in \{1,-1\}} \hat{p}_{z_{1},z_{2},\ldots,z_{t}}\log \hat{p}_{z_{1},z_{2},\ldots,z_{t}}, \end{array} $$ where \(\hat {p}_{z_{1},z_{2},\ldots,z_{t}}\) is the empirical probability of { Z 1 = z 1 , Z 2 = z 2 ,…, Z t = z t }. By Lemma 6 in Additional file 1 , the plug-in estimate of Then we establish the following theorem about the sample complexity for estimation of . Theorem 5 For 0< ε , δ <1, choose $$N\ge \frac{e^{2}}{(e-2)^{2}}\widetilde{N}(\varepsilon,\delta)\left[\log \widetilde{N}(\varepsilon,\delta)\right]^{2}, $$ where e is the base of the natural logarithm and $$\widetilde{N}(\varepsilon,\delta)=\frac{2^{2|S|+3}}{\delta^{2}}\log \frac{\max\left\{2^{|S|+1},6\right\}}{\varepsilon}, $$ then we have See the proof in Additional file 1 . □ We note that the sample complexity is exponential over the interaction order to detect. Results With these established theoretical results, we now empirically test the effectiveness of the information-theoretic synergistic interaction measures, including our proposed adjusted multivariate synergy defined in ( 3 ). Simulated data We randomly generate 1000 logistic regression models. Each model contains 50 features. We randomly choose 3 features and 3 interacting pairs as contributing terms to the outcome for this model, and randomly assign a parameter drawn from a uniform distribution over [ 1,2] quantifying the effect size for each of these features and pairs. For each logistic regression model, we generate random training sets of 500, 1000, 1500, 2000, 2500, and 3000 samples. Each training sample consists of an observation of each covariate X i drawn from a two-point distribution (Pr( X i =1)= p i and Pr( X i =−1)=1− p i ), for 1≤ i ≤50, and a binary outcome from the conditional distributions ( 1 ), ( 2 ), where p i is randomly drawn from a uniform distribution over {0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9}. With these randomly generated training samples of different sizes, we detect the three chosen pairs in the logistic regression model using six different information-theoretic measures: 1) multivariate synergy [ 13 , 37 ], 2) adjusted multivariate synergy, 3) Schneidman’s normalized synergy [ 40 ], 4) Ignac’s normalized mutual information [ 41 ], 5) Watabene’s total correlation [ 28 ], and 6) Han’s dual total correlation [ 30 ]. For each measure, we consider the three pairs with the largest estimated values of this measure as the interacting pairs, and evaluate the detection correctness. Figure 1 shows that the methods based on multivariate synergy, adjusted multivariate synergy, and Ignac’s normalized mutual information highly outperform the other three methods based on Watabene’s total correlation, Han’s dual total correlation, and Schneidman’s normalized synergy. Furthermore, the algorithm based on the multivariate synergy or Ignac’s normalized mutual information performs the best when the number of samples is at most 1000, while the method of ranking the adjusted multivariate synergies achieves a roughly 5% higher accuracy than that of ranking the multivariate synergies or Schneidman’s normalized synergies when the number of the samples are 1500, 2000, 2500, and 3000. By the independent two-sample t-test, the corresponding p -value is less than 10 −5 , which shows the statistically significant difference between the detection accuracies. The adjusted multivariate synergy is directly related to the interaction parameter according to Corollary 3. Thus it can well capture the interactive effect via the normalization. It needs a little more samples to get a relatively accurate estimate (both its numerator and denominator need to be estimated) compared to multivariate synergy. We conjecture that the combination of these two measures probably could serve as a more useful tool for interaction detection. The other methods based on Schneidman’s normalized synergy, Watabene’s total correlation, or Han’s dual total correlation have inferior performance when identifying the interactions, since these measures have no clear relationships with the interaction parameters in logistic regression models. Fig. 1 Detection accuracies of interactive effects by the methods based on six information-theoretic measures (with 50 features) We further study the relationship between the sample number and the detection accuracy of the interactive effects. It is observed that the curves obtained by both the multivariate synergy and the adjusted multivariate synergy fit very well with a logarithmic relation: i.e., $$\textrm{sample number \textit{N}} \propto \log(1/\textrm{detection error rate \(\varepsilon\)}), $$ closely matching the derived theoretical bound on sample complexity in Theorem 5. Here we remark that the same conclusion can be drawn with different settings on the number of features in the model. We also generate 1000 logistic regression models, each of which contains 20 features. In each model, we randomly generate 200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, and 2000 samples by the same way as in the previous simulation. Figure 2 illustrates the prediction accuracies of the models based on the six aforementioned theoretic measures. The same trends as discussed earlier can be observed in the figure. Fig. 2 Detection accuracies of the methods based on six information-theoretic measures (with 20 features) Although we derive the theoretical results with the assumption that the features are independent of each other, the multivariate synergy and the adjusted multivariate synergy can still serve as good measures of interactions for the cases when the features are weakly dependent in practice. We further simulate such weakly dependent cases to empirically evaluate their interaction detection performance. In each simulated full logistic regression model, we first randomly choose K from a uniform distribution on {1,−1}, and then each covariate X i is drawn from a conditional probability Pr( X i =1| K )= p i + μ K and Pr( X i =−1| K )= q i − μ K , for 1≤ i ≤50, with μ controlling the dependency among covariates. Here, p i is randomly chosen from a uniform distribution over {0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9} as in the previous simulations. The output Y is generated by the conditional probability ( 1 ) and ( 2 ). Straightforward calculation shows that each pair of features are dependent with covariance 4 μ 2 and coefficient correlation ρ ∈ [4 μ 2 ,100 μ 2 /9], when μ ≠0. Figure 3 plots the detection accuracies of the methods based on multivariate synergy or adjusted multivariate synergy with different μ ( μ =0, 0.05, 0.08, or 0.1). The trends are clear that these measures still can help accurately identify the interactions even when all pairs of features are weakly dependent, especially when μ is small (< 0.1). The relationship between the sample complexity and detection error rate still follows the derived logarithmic relationship with weakly dependent features. Fig. 3 Detection accuracies of the interactive effects by the methods based on multivariate synergy and adjusted multivariate synergy with different μ Real-world GWAS data Type 1 Diabetes (T1D), previously known as Insulin-Dependent Diabetes Mellitus (IDDM), is an autoimmune disease resulting from the deficiency of insulin. This disease is conjectured to be caused by both genetic and environmental factors and has attracted tremendous research interests, especially in detecting pairwise or high-order genome-wide interactions for T1D [ 42 – 46 ]. Here, we apply our proposed adjusted multivariate synergy to the case-control data extracted from the Wellcome Trust Case Control Consortium (WTCCC) [ 47 ]. The WTCCC T1D data set includes 2000 case samples and 1500 control samples, each of which contains around 500,000 SNPs. In [ 42 ], the BOOST method, a two-stage (screening and testing) search method, selects the pairs without significant main effects and with significant interactions. They listed all 91 such pairs in Table S6 of [ 42 ] (referred as “Table W” in this paper), each of which satisfies that the genome distance between the two SNPs’ chromosomal positions is at least 1Mb. To make the comparison between our method and theirs, we pick 73 SNPs mentioned in the table, and run our algorithm on the part of the data containing the information related to these SNPs. We estimate the adjusted multivariate synergy for each pair of these SNPs. The pairs with the 15 largest estimates are shown in Table 1 . Table 1 The top 15 pairs with the largest adjusted multivariate synergy estimates SNP A