
— @djrothkopf 
function notifyResize(height) {height = height ? height : document.documentElement.offsetHeight; var resized = false; if (window.donkey && donkey.resize) {donkey.resize(height); resized = true;}if (parent && parent._resizeIframe) {var obj = {iframe: window.frameElement, height: height}; parent._resizeIframe(obj); resized = true;}if (window.location && window.location.hash === “#amp=1”&& window.parent && window.parent.postMessage) {window.parent.postMessage({sentinel: “amp”, type: “embed-size”, height: height}, “*”);}if (window.webkit && window.webkit.messageHandlers && window.webkit.messageHandlers.resize) {window.webkit.messageHandlers.resize.postMessage(height); resized = true;}return resized;}twttr.events.bind(‘rendered’, function (event) {notifyResize();}); twttr.events.bind(‘resize’, function (event) {notifyResize();});if (parent && parent._resizeIframe) {var maxWidth = parseInt(window.frameElement.getAttribute(“width”)); if ( 500 < maxWidth) {window.frameElement.setAttribute("width", "500");}} 
How did it work? Originally a British academic named Aleksandr Kogan got permission from Facebook to collect data on its users through several of those innocuous-seeming quizzes, which then granted access to all their profile information, where they live, what they do, what they read, what they click — an amazingly detailed profile of their personal information. Amazingly, at this time of collection, Facebook’s Terms of Service and API were so poorly crafted that this same access also gave Kogan full access to all those users’ friends — so quickly he had 50 million profiles, which Kogan then allegedly illegally sold to Cambridge Analytica. 
Facebook is now attempting to navigate a full-blown crisis situation. Earlier this week the company’s stock lost some 7% of its value, while several shareholders are suing. Now the company is facing a probe from the Federal Trade Commission, while at least two state Attorney Generals have issued sharp statements expressing concern over the company’s handling of its sensitive user data. 
Matters are not at all helped by the fact that the psychologist Joseph Chancellor, who helped found Cambridge Analytica and its ( largely bogus ) psychographic targeting method, is now an employee at Facebook. 
The Facebook data harvesting scandal is in many ways like a classic case study in corporate foreign policy . The responses and decisions they make going forward to regain public trust, credibility, and reach agreements with stakeholders in the policy community to stave off new regulatory impositions are paramount to the company’s survival. 
So far, Facebook’s response to the crisis is falling quite short. Observers have noted that neither CEO Mark Zuckerberg nor COO Sheryl Sandberg have been bothered to appear in public. Actually, they haven’t bothered to attend Facebook’s own internal employee town hall on the scandal . There is clear internal discord over the public response, underscored by the resignation of the company’s chief security officer Alex Stamos, right at a moment in which the company needs desperately to display a resolute, united front. 
At the root of Facebook’s problematic response is a fundamental failure to understand the concerns of their audience. Aside from publishing a blog post announcing that Cambridge Analytica and SCL Group had been banned from Facebook, some of the company executives appear hung up on the semantics of whether or not this should be called a “ data breach ,” when in fact they freely gave away the personal data of 50 million users by their own decision. But this is really not the point, in the public’s view. No one cares how good your security is if you are selling and giving away private user data, failing to verify that such data is deleted as agreed, especially for a political campaign that allegedly aimed to prey on voters’ fears. 
Of course, Facebook was already in trouble before this scandal took place. Last fall, in hearings before the Senate Judiciary Committee investigating Russian meddling in the 2016 election, it was revealed that Facebook had allowed Russian and Russia-linked entities to fund millions of dollars of paid political ads, ranging from 2nd amendment issues to provocative racial comments meant to sow discord and heighten tensions in the country. New regulations were put in place requiring Facebook to disclose who is paying for political ads, but these regulations still fall far short of the requirements of political ads placed in traditional media. 
When presented with numerous opportunities to self-regulate and self-police itself on these issues, Facebook has consistently fallen short. Meanwhile, Members of Congress are becoming more and more vocal, demanding that Zuckerberg himself appear in hearings to answer questions, while others are debating European-style regulations on social media companies. 
The risk facing Big Tech is significant. If in fact Facebook violated its 2011 consent decree with the FTC on user privacy, they could face fines of up to $40,000 per infraction — so with 50 million users have their data stolen, in theory the company could be fined upward of $2 trillion. Writing on WIRED , Nicholas Thompson and Fred Vogelstein point out that Facebook’s problems could get much, much worse — especially if it the stolen data was found to have made its way into the hands of Russian-funded troll farms, thus placing them in the crosshairs of the Mueller investigation. 
Facebook is not alone in their failure to self-regulate, of course. Twitter has been another source of major public concern since the 2016 election, as the company has apparently done so little to stem the explosion of fake accounts, bots, false information, inflammatory hate speech, and undisclosed political advertising from shady foreign sources. They could likely be next to face political consequences for poor crisis planning. 
The proclamations of Facebook’s demise are certainly premature, and it is hard to envision our current Congress having the wherewithal to get anywhere close to imposing an effective regulatory regime over social media companies. But the company’s response to the current situation is nevertheless crucial to maintain users. They not only have to drastically update the transparency surrounding how they use data, allowing users more clarity to opt out of such invasive practices, but also they need to get on their message — and do it very quickly before it’s too late. 